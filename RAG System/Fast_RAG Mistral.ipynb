{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 9695908,
          "sourceType": "datasetVersion",
          "datasetId": 5928411
        },
        {
          "sourceId": 9695917,
          "sourceType": "datasetVersion",
          "datasetId": 5928418
        }
      ],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03cb9a2115984860b44a25f542caa065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c6fb9dc73ca42cf8969f3443f304db7",
              "IPY_MODEL_5233a850319b44abacbea9e92fdc67ff",
              "IPY_MODEL_500bcd73a6a64aec9b89e7b4c18ed151"
            ],
            "layout": "IPY_MODEL_b7fc54acbf384d7f8d7f73b824f62947"
          }
        },
        "3c6fb9dc73ca42cf8969f3443f304db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0dac58cc3474956831dd62d860e79d3",
            "placeholder": "​",
            "style": "IPY_MODEL_d37513425e80487888cee97544ad32d4",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "5233a850319b44abacbea9e92fdc67ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be8d334d19b3466eaeea0638d1a1a52b",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b71c59d6137c48f1aa18de8f2f2efbbf",
            "value": 4
          }
        },
        "500bcd73a6a64aec9b89e7b4c18ed151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b9403bb9bc84715868a3606320cbc4e",
            "placeholder": "​",
            "style": "IPY_MODEL_18f51e741714410aabc4a753d08ffe70",
            "value": " 4/4 [01:38&lt;00:00, 21.33s/it]"
          }
        },
        "b7fc54acbf384d7f8d7f73b824f62947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0dac58cc3474956831dd62d860e79d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d37513425e80487888cee97544ad32d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be8d334d19b3466eaeea0638d1a1a52b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b71c59d6137c48f1aa18de8f2f2efbbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b9403bb9bc84715868a3606320cbc4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18f51e741714410aabc4a753d08ffe70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Retreival System"
      ],
      "metadata": {
        "id": "zD1yLKdKMeFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is based heavily on the tutorial from https://huggingface.co/learn/cookbook/en/advanced_rag as recommended in the course. We should probably credit it."
      ],
      "metadata": {
        "id": "GxP8xdhRMeFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EAO9g_hg0KQD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters to test:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* embedding models\n",
        "\n",
        "* distance strategies for vector store\n",
        "\n",
        "* chunk size\n",
        "\n",
        "* overlap size\n",
        "\n",
        "* k value for top_k\n",
        "\n",
        "* model used for LLM\n",
        "\n",
        "* alter generated prompt\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iJukJBF5MIdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://jbbernardin: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@github.com//BainMcHaleCMU/ANLP_RAG.git\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vwvv3q6mzTe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "RB8EmVkNzYLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-community transformers sentence-transformers faiss-gpu bitsandbytes"
      ],
      "metadata": {
        "id": "jmG3wBh7bE98",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:21:31.098831Z",
          "iopub.execute_input": "2024-10-22T19:21:31.099552Z",
          "iopub.status.idle": "2024-10-22T19:21:57.732321Z",
          "shell.execute_reply.started": "2024-10-22T19:21:31.099499Z",
          "shell.execute_reply": "2024-10-22T19:21:57.731239Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "aniJEiDdb7ZZ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:21:57.734413Z",
          "iopub.execute_input": "2024-10-22T19:21:57.734790Z",
          "iopub.status.idle": "2024-10-22T19:21:59.203080Z",
          "shell.execute_reply.started": "2024-10-22T19:21:57.734749Z",
          "shell.execute_reply": "2024-10-22T19:21:59.201731Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# To get the value of the max sequence_length, we will query the underlying `SentenceTransformer` object used for embeddings\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "print(f\"Model's maximum sequence length: {SentenceTransformer('all-mpnet-base-v2').max_seq_length}\")"
      ],
      "metadata": {
        "id": "CBsNAPtKiiZM",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:21:59.204420Z",
          "iopub.execute_input": "2024-10-22T19:21:59.204877Z",
          "iopub.status.idle": "2024-10-22T19:22:23.987799Z",
          "shell.execute_reply.started": "2024-10-22T19:21:59.204841Z",
          "shell.execute_reply": "2024-10-22T19:22:23.986601Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb6f544-d26f-43b1-caf2-cbf08c243d62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's maximum sequence length: 384\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "\n",
        "df = pd.read_csv('merged_data.csv')\n",
        "\n",
        "\n",
        "# Split text into chunks\n",
        "\n",
        "TEXT_SEPARATORS = [\n",
        "\n",
        "    \"\\n\\n\",\n",
        "\n",
        "    \"\\n\",\n",
        "\n",
        "    \".\",\n",
        "\n",
        "    \" \",\n",
        "\n",
        "    \"\",\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "\n",
        "    chunk_size=384-64, # selected to stay under 384 max size for all-mpnet-base-v2\n",
        "\n",
        "    chunk_overlap=50, # arbitrarily pick how much across chunks\n",
        "\n",
        "    add_start_index=True,  # If `True`, includes chunk's start index in metadata\n",
        "\n",
        "    strip_whitespace=True,  # If `True`, strips whitespace from the start and end of every document\n",
        "\n",
        "    separators=TEXT_SEPARATORS,\n",
        "\n",
        ")\n",
        "\n",
        "texts = []\n",
        "\n",
        "metadatas = []\n",
        "\n",
        "\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "\n",
        "    try:\n",
        "\n",
        "      chunks = text_splitter.split_text(row['text'])\n",
        "\n",
        "      texts.extend(chunks)\n",
        "\n",
        "      metadatas.extend([{'source': row['source']}] * len(chunks))\n",
        "\n",
        "    except:\n",
        "\n",
        "      print(f\"source {row['source']} corrupted\")"
      ],
      "metadata": {
        "id": "oZlCrH_Sb8mF",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:22:23.990737Z",
          "iopub.execute_input": "2024-10-22T19:22:23.991580Z",
          "iopub.status.idle": "2024-10-22T19:22:30.164664Z",
          "shell.execute_reply.started": "2024-10-22T19:22:23.991541Z",
          "shell.execute_reply": "2024-10-22T19:22:30.163829Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f8a713d-74aa-4178-ce4f-15f8c150d8a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source https://onestoppgh.pittsburghpa.gov/pghprod/pub/lms/Login.aspx corrupted\n",
            "source https://www.cmu.edu/dietrich/rss-feeds/news-rss.rss corrupted\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = [len(text) for text in texts]\n",
        "\n",
        "# Plot the distribution of text lengths, counted as the number of tokens\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = pd.Series(lengths).hist()\n",
        "\n",
        "plt.title(\"Distribution of document lengths in the knowledge base (in count of tokens)\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lLYIznRkeDQ4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:22:30.201058Z",
          "iopub.execute_input": "2024-10-22T19:22:30.201618Z",
          "iopub.status.idle": "2024-10-22T19:22:30.565848Z",
          "shell.execute_reply.started": "2024-10-22T19:22:30.201582Z",
          "shell.execute_reply": "2024-10-22T19:22:30.564923Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "4d7aa056-64cd-4742-c465-9911c6c3e97c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import normalize\n",
        "from transformers import AutoTokenizer, AutoModel, T5EncoderModel\n",
        "import torch"
      ],
      "metadata": {
        "id": "Un1dfaqcY9Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Initialize the Hugging Face Embedding Model\n",
        "model_name = 'sentence-transformers/sentence-t5-large'  # Example model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# embedder_model = AutoModel.from_pretrained(model_name)\n",
        "embedder_model = T5EncoderModel.from_pretrained(model_name)  # Use only the encoder\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "embedder_model.to(device)\n",
        "embedder_model.eval()\n",
        "\n",
        "# Step 2: Define a function to generate embeddings\n",
        "def generate_embeddings(texts, tokenizer, embedder_model, batch_size=32):\n",
        "    embeddings = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch_texts = texts[i:i + batch_size]\n",
        "            inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors='pt')\n",
        "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "            outputs = embedder_model(**inputs)\n",
        "            attention_mask = inputs['attention_mask']\n",
        "            embeddings_batch = mean_pooling(outputs, attention_mask)\n",
        "            embeddings.append(embeddings_batch.cpu().numpy())\n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output.last_hidden_state\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, dim=1)\n",
        "    sum_mask = torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9)\n",
        "    return sum_embeddings / sum_mask\n",
        "\n",
        "# Step 3: Load your texts\n",
        "# already loaded\n",
        "\n",
        "# Step 4: Generate embeddings\n",
        "embeddings = generate_embeddings(texts, tokenizer, embedder_model, batch_size=32).astype('float32')\n",
        "\n",
        "# Step 5: Dimensionality Reduction\n",
        "# pca = PCA(n_components=512)\n",
        "# reduced_embeddings = pca.fit_transform(embeddings)\n",
        "\n",
        "# Step 6: Normalize for Cosine Similarity\n",
        "# normalized_embeddings = normalize(reduced_embeddings, norm='l2', axis=1)\n",
        "normalized_embeddings = normalize(embeddings, norm='l2', axis=1)\n",
        "\n",
        "# Step 7: Initialize FAISS Index\n",
        "n_clusters = 200\n",
        "m = 16\n",
        "nbits = 8\n",
        "quantizer = faiss.IndexFlatL2(normalized_embeddings.shape[1])\n",
        "index = faiss.IndexIVFPQ(quantizer, normalized_embeddings.shape[1], n_clusters, m, nbits)\n",
        "\n",
        "# Step 8: Move Index to GPU and Train\n",
        "res = faiss.StandardGpuResources()\n",
        "gpu_index = faiss.index_cpu_to_gpu(res, 0, index)\n",
        "gpu_index.train(normalized_embeddings)\n",
        "\n",
        "# Step 9: Add Embeddings to the Index\n",
        "gpu_index.add(normalized_embeddings)\n",
        "\n",
        "# Step 10: Define Batch Search Function\n",
        "# def batch_search(gpu_index, query_texts, tokenizer, embedder_model, pca, batch_size=32, k=5):\n",
        "def batch_search(gpu_index, query_texts, tokenizer, embedder_model, batch_size=32, k=5):\n",
        "\n",
        "    query_embeddings = generate_embeddings(query_texts, tokenizer, embedder_model, batch_size=batch_size)\n",
        "    # reduced_queries = pca.transform(query_embeddings)\n",
        "    # normalized_queries = normalize(reduced_queries, norm='l2', axis=1)\n",
        "    normalized_queries = normalize(query_embeddings, norm='l2', axis=1)\n",
        "\n",
        "    results = []\n",
        "    for i in range(0, len(normalized_queries), batch_size):\n",
        "        batch = normalized_queries[i:i + batch_size]\n",
        "        D, I = gpu_index.search(batch, k)\n",
        "        results.extend(zip(D, I))\n",
        "    return results"
      ],
      "metadata": {
        "id": "8CoC5cGJ3rLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reader"
      ],
      "metadata": {
        "id": "A4de5-jvO0dO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_template():\n",
        "\n",
        "  prompt_in_chat_format = [\n",
        "\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "\n",
        "      \"content\": \"\"\"Using the information contained in the context,\n",
        "        give a concise answer to the question.\n",
        "        if possible limit your answer to single or a few words for who, when, where questions.\n",
        "        wherever possible extract name, date, or title without additional explanations.\n",
        "        Respond only to the question asked, response should be concise and relevant to the question.\n",
        "        You should do short answers format responses. DO NOT PUT \"ANSWER\" BEFORE THE ANSWER.\n",
        "        Don't answer in full sentences. For example, say \"12\" instead of \"The answer is 12.\"\n",
        "        \"\"\",\n",
        "      },\n",
        "\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": \"\"\"Context:\n",
        "          {context}\n",
        "          ---\n",
        "          Here are some examples of question answer pairs:\n",
        "\n",
        "          Who is Pittsburgh named after?\n",
        "          William Pitt\n",
        "\n",
        "          What famous machine learning venue had its first conference in Pittsburgh in 1980?\n",
        "          ICML\n",
        "\n",
        "          What musical artist is performing at PPG Arena on October 13?\n",
        "          Billie Eilish\n",
        "          ---\n",
        "          Don't answer in full sentences. For example, say \"12\" instead of \"The answer is 12.\"\n",
        "          Now here is the question for you to answer:\n",
        "          {question}\n",
        "\n",
        "          \"\"\",\n",
        "      },\n",
        "\n",
        "  ]\n",
        "\n",
        "  RAG_PROMPT_TEMPLATE = inference_tokenizer.apply_chat_template(\n",
        "\n",
        "      prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n",
        "\n",
        "  )\n",
        "\n",
        "  return RAG_PROMPT_TEMPLATE\n",
        "\n",
        "def create_prompts(template, queries, contexts):\n",
        "  return [template.format(question=query, context=context) for query, context in zip(queries, contexts)]\n",
        "\n",
        "def create_contexts(queries, k=5):\n",
        "  search_results = batch_search(gpu_index, queries, tokenizer, embedder_model, pca, batch_size=32, k=k)\n",
        "  contexts = []\n",
        "  for query, (distances, indices) in zip(queries, search_results):\n",
        "    context = \"\\n\\n\".join([texts[i] for i in indices])\n",
        "    contexts.append(context)\n",
        "  return contexts"
      ],
      "metadata": {
        "id": "lygyo49_O1Nf",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:24:04.599103Z",
          "iopub.execute_input": "2024-10-22T19:24:04.599416Z",
          "iopub.status.idle": "2024-10-22T19:24:04.608775Z",
          "shell.execute_reply.started": "2024-10-22T19:24:04.599383Z",
          "shell.execute_reply": "2024-10-22T19:24:04.607818Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "import torch\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
      ],
      "metadata": {
        "id": "pTZ9J3K8aNxQ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:24:04.609824Z",
          "iopub.execute_input": "2024-10-22T19:24:04.610113Z",
          "iopub.status.idle": "2024-10-22T19:24:05.774867Z",
          "shell.execute_reply.started": "2024-10-22T19:24:04.610081Z",
          "shell.execute_reply": "2024-10-22T19:24:05.773761Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")\n",
        "\n",
        "# !pip install vllm mistral_common\n",
        "from vllm import LLM\n",
        "from vllm.sampling_params import SamplingParams\n",
        "\n",
        "READER_MODEL_NAME = \"mistralai/Ministral-8B-Instruct-2410\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "\n",
        "    load_in_4bit=True,\n",
        "\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "\n",
        ")\n",
        "\n",
        "inference_tokenizer = AutoTokenizer.from_pretrained(READER_MODEL_NAME, token=\"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\")\n",
        "\n",
        "inference_model = AutoModelForCausalLM.from_pretrained(READER_MODEL_NAME, quantization_config=bnb_config, token=\"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\")\n",
        "\n",
        "inference_model.eval()"
      ],
      "metadata": {
        "id": "bfpSbBDQQ46S",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:24:05.776086Z",
          "iopub.execute_input": "2024-10-22T19:24:05.776444Z",
          "iopub.status.idle": "2024-10-22T19:24:40.885212Z",
          "shell.execute_reply.started": "2024-10-22T19:24:05.776407Z",
          "shell.execute_reply": "2024-10-22T19:24:40.884226Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635,
          "referenced_widgets": [
            "03cb9a2115984860b44a25f542caa065",
            "3c6fb9dc73ca42cf8969f3443f304db7",
            "5233a850319b44abacbea9e92fdc67ff",
            "500bcd73a6a64aec9b89e7b4c18ed151",
            "b7fc54acbf384d7f8d7f73b824f62947",
            "f0dac58cc3474956831dd62d860e79d3",
            "d37513425e80487888cee97544ad32d4",
            "be8d334d19b3466eaeea0638d1a1a52b",
            "b71c59d6137c48f1aa18de8f2f2efbbf",
            "7b9403bb9bc84715868a3606320cbc4e",
            "18f51e741714410aabc4a753d08ffe70"
          ]
        },
        "outputId": "c602c26a-ab07-49d0-de38-9a4f0bca6fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03cb9a2115984860b44a25f542caa065"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MistralForCausalLM(\n",
              "  (model): MistralModel(\n",
              "    (embed_tokens): Embedding(131072, 4096)\n",
              "    (layers): ModuleList(\n",
              "      (0-35): 36 x MistralDecoderLayer(\n",
              "        (self_attn): MistralSdpaAttention(\n",
              "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (rotary_emb): MistralRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): MistralMLP(\n",
              "          (gate_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
              "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=131072, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the prompt template\n",
        "\n",
        "template = create_template()\n",
        "\n",
        "# Initialize LLM Pipeline\n",
        "\n",
        "READER_LLM = pipeline(\n",
        "\n",
        "    model=inference_model,\n",
        "\n",
        "    tokenizer=inference_tokenizer,\n",
        "\n",
        "    task=\"text-generation\",\n",
        "\n",
        "    do_sample=True,\n",
        "\n",
        "    temperature=0.01,\n",
        "\n",
        "    repetition_penalty=1.1,\n",
        "\n",
        "    return_full_text=False,\n",
        "\n",
        "    max_new_tokens=50,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "rlVNWiLSWJR4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:24:40.886553Z",
          "iopub.execute_input": "2024-10-22T19:24:40.886894Z",
          "iopub.status.idle": "2024-10-22T19:24:40.903431Z",
          "shell.execute_reply.started": "2024-10-22T19:24:40.886858Z",
          "shell.execute_reply": "2024-10-22T19:24:40.902390Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\"What is the nickname for Pittsburgh?\", \"Who is Pittsburgh named after?\"]\n",
        "\n",
        "contexts = create_contexts(queries, k=20)\n",
        "\n",
        "prompts = create_prompts(template, queries, contexts)\n",
        "\n",
        "for prompt in prompts:\n",
        "\n",
        "  print(READER_LLM(prompt)[0]['generated_text'])"
      ],
      "metadata": {
        "id": "KFcCtWWWWqK3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:24:40.904742Z",
          "iopub.execute_input": "2024-10-22T19:24:40.905407Z",
          "iopub.status.idle": "2024-10-22T19:25:04.592162Z",
          "shell.execute_reply.started": "2024-10-22T19:24:40.905346Z",
          "shell.execute_reply": "2024-10-22T19:25:04.591231Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "feaecba4-f9dd-4788-8e7f-b96c329949f2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pca' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ac4cd03687d8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"What is the nickname for Pittsburgh?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Who is Pittsburgh named after?\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcontexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_contexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-3e1340b3fe40>\u001b[0m in \u001b[0;36mcreate_contexts\u001b[0;34m(queries, k)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_contexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m   \u001b[0msearch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedder_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0mcontexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pca' is not defined"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def get_answer(questions):\n",
        "\n",
        "    # Simulating a RAG system query\n",
        "\n",
        "    contexts = create_contexts(questions, k=10)\n",
        "\n",
        "    prompts = create_prompts(template, questions, contexts)\n",
        "\n",
        "    answers = []\n",
        "\n",
        "    for prompt in tqdm(prompts):\n",
        "        answers.append(READER_LLM(prompt)[0]['generated_text'])\n",
        "\n",
        "    return answers\n",
        "\n",
        "def generate_answers(input_file, output_file, batch_size=32):\n",
        "\n",
        "    with open(input_file, 'r') as file:\n",
        "\n",
        "        questions = file.readlines()\n",
        "\n",
        "    answers = []\n",
        "\n",
        "    print(\"Number of Batches: \" + str(len(questions)))\n",
        "\n",
        "    # Split questions into batches\n",
        "    for i in tqdm(range(0, len(questions), batch_size)):\n",
        "        batch_questions = questions[i:i + batch_size]  # Get a batch of questions\n",
        "        batch_questions = [q.strip() for q in batch_questions if q.strip()]  # Remove empty lines\n",
        "\n",
        "        # Get answers for the batch\n",
        "        batch_answers = get_answer(batch_questions)  # Call get_answer with the batch\n",
        "\n",
        "        # Append answers to the main list\n",
        "        for index, answer in enumerate(batch_answers):\n",
        "            answers.append(f'{answer}')  # Adjust question numbering\n",
        "\n",
        "\n",
        "    with open(output_file, 'w') as file:\n",
        "\n",
        "        for answer in answers:\n",
        "\n",
        "            file.write(answer.replace(\"\\n\", \"\\t\") + '\\n') # need replace for formatting reasons\n",
        "\n",
        "            print(answer)  # Print each answer as it's generated"
      ],
      "metadata": {
        "id": "Om0Hwr2mCT5L",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:32:27.554545Z",
          "iopub.execute_input": "2024-10-22T19:32:27.555420Z",
          "iopub.status.idle": "2024-10-22T19:32:27.565955Z",
          "shell.execute_reply.started": "2024-10-22T19:32:27.555363Z",
          "shell.execute_reply": "2024-10-22T19:32:27.564594Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage example:\n",
        "\n",
        "generate_answers(\"questions.txt\", \"generated_answers.txt\")"
      ],
      "metadata": {
        "id": "HCVCF2Vo1MBE",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:55:27.514069Z",
          "iopub.execute_input": "2024-10-22T19:55:27.514497Z",
          "iopub.status.idle": "2024-10-22T19:55:55.950096Z",
          "shell.execute_reply.started": "2024-10-22T19:55:27.514457Z",
          "shell.execute_reply": "2024-10-22T19:55:55.947251Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "C5r65cE30nM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "# Function to normalize text by removing articles and punctuation and lowercasing\n",
        "\n",
        "def normalize_answer(s):\n",
        "\n",
        "    def remove_articles(text):\n",
        "\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "\n",
        "    def remove_punctuation(text):\n",
        "\n",
        "        return re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "\n",
        "\n",
        "    def lowercase(text):\n",
        "\n",
        "        return text.lower()\n",
        "\n",
        "\n",
        "\n",
        "    return remove_articles(remove_punctuation(lowercase(s))).strip()\n",
        "\n",
        "\n",
        "\n",
        "# Function to compute Exact Match (EM)\n",
        "\n",
        "def exact_match_score(prediction, ground_truth):\n",
        "\n",
        "    return int(normalize_answer(prediction) == normalize_answer(ground_truth))\n",
        "\n",
        "\n",
        "\n",
        "# Function to compute F1 Score\n",
        "\n",
        "def f1_score_single(prediction, ground_truth):\n",
        "\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "\n",
        "\n",
        "\n",
        "    common_tokens = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "\n",
        "    num_same = sum(common_tokens.values())\n",
        "\n",
        "\n",
        "\n",
        "    if num_same == 0:\n",
        "\n",
        "        return 0\n",
        "\n",
        "\n",
        "\n",
        "    precision = num_same / len(prediction_tokens)\n",
        "\n",
        "    recall = num_same / len(ground_truth_tokens)\n",
        "\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "\n",
        "\n",
        "    return f1\n",
        "\n",
        "\n",
        "\n",
        "# Function to compute recall\n",
        "\n",
        "def recall_score_single(prediction, ground_truth):\n",
        "\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "\n",
        "\n",
        "\n",
        "    common_tokens = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "\n",
        "    num_same = sum(common_tokens.values())\n",
        "\n",
        "\n",
        "\n",
        "    if len(ground_truth_tokens) == 0:\n",
        "\n",
        "        return 0\n",
        "\n",
        "    recall = num_same / len(ground_truth_tokens)\n",
        "\n",
        "    return recall"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:25:05.099918Z",
          "iopub.status.idle": "2024-10-22T19:25:05.100323Z",
          "shell.execute_reply.started": "2024-10-22T19:25:05.100110Z",
          "shell.execute_reply": "2024-10-22T19:25:05.100129Z"
        },
        "id": "k7OjTSdG0nM_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the reference and generated answers\n",
        "\n",
        "with open('reference_answers.txt', 'r') as f:\n",
        "\n",
        "    reference_answers = f.readlines()\n",
        "\n",
        "\n",
        "\n",
        "with open('generated_answers.txt', 'r') as f:\n",
        "\n",
        "    generated_answers = f.readlines()\n",
        "\n",
        "\n",
        "\n",
        "# Ensure the files have the same number of answers\n",
        "\n",
        "assert len(reference_answers) == len(generated_answers), \"Mismatch in number of answers.\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:25:05.101925Z",
          "iopub.status.idle": "2024-10-22T19:25:05.102288Z",
          "shell.execute_reply.started": "2024-10-22T19:25:05.102099Z",
          "shell.execute_reply": "2024-10-22T19:25:05.102116Z"
        },
        "id": "wSWxeuvU0nNA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics\n",
        "\n",
        "total_em = 0\n",
        "\n",
        "total_f1 = 0\n",
        "\n",
        "total_recall = 0\n",
        "\n",
        "\n",
        "\n",
        "# Iterate over all answers and compute metrics\n",
        "\n",
        "for ref_answer, gen_answer in zip(reference_answers, generated_answers):\n",
        "\n",
        "    em = exact_match_score(gen_answer.strip(), ref_answer.strip())\n",
        "\n",
        "    f1 = f1_score_single(gen_answer.strip(), ref_answer.strip())\n",
        "\n",
        "    recall = recall_score_single(gen_answer.strip(), ref_answer.strip())\n",
        "\n",
        "\n",
        "\n",
        "    total_em += em\n",
        "\n",
        "    total_f1 += f1\n",
        "\n",
        "    total_recall += recall\n",
        "\n",
        "# Average the metrics over all the questions\n",
        "\n",
        "num_questions = len(reference_answers)\n",
        "\n",
        "average_em = total_em / num_questions\n",
        "\n",
        "average_f1 = total_f1 / num_questions\n",
        "\n",
        "average_recall = total_recall / num_questions\n",
        "\n",
        "\n",
        "\n",
        "# Display the results\n",
        "\n",
        "print(f\"Exact Match: {average_em * 100:.2f}%\")\n",
        "\n",
        "print(f\"F1 Score: {average_f1 * 100:.2f}%\")\n",
        "\n",
        "print(f\"Recall: {average_recall * 100:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:25:05.103716Z",
          "iopub.status.idle": "2024-10-22T19:25:05.104199Z",
          "shell.execute_reply.started": "2024-10-22T19:25:05.103892Z",
          "shell.execute_reply": "2024-10-22T19:25:05.103911Z"
        },
        "id": "F5TNkxRr0nNA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jopj20IsQWBW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}