{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 9695908,
          "sourceType": "datasetVersion",
          "datasetId": 5928411
        },
        {
          "sourceId": 9695917,
          "sourceType": "datasetVersion",
          "datasetId": 5928418
        }
      ],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Retreival System"
      ],
      "metadata": {
        "id": "zD1yLKdKMeFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is based heavily on the tutorial from https://huggingface.co/learn/cookbook/en/advanced_rag as recommended in the course. We should probably credit it."
      ],
      "metadata": {
        "id": "GxP8xdhRMeFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters to test:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* embedding models\n",
        "\n",
        "* distance strategies for vector store\n",
        "\n",
        "* chunk size\n",
        "\n",
        "* overlap size\n",
        "\n",
        "* k value for top_k\n",
        "\n",
        "* model used for LLM\n",
        "\n",
        "* alter generated prompt\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iJukJBF5MIdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-community transformers sentence-transformers faiss-gpu bitsandbytes"
      ],
      "metadata": {
        "id": "jmG3wBh7bE98",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:21:31.098831Z",
          "iopub.execute_input": "2024-10-22T19:21:31.099552Z",
          "iopub.status.idle": "2024-10-22T19:21:57.732321Z",
          "shell.execute_reply.started": "2024-10-22T19:21:31.099499Z",
          "shell.execute_reply": "2024-10-22T19:21:57.731239Z"
        }
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "aniJEiDdb7ZZ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:21:57.734413Z",
          "iopub.execute_input": "2024-10-22T19:21:57.734790Z",
          "iopub.status.idle": "2024-10-22T19:21:59.203080Z",
          "shell.execute_reply.started": "2024-10-22T19:21:57.734749Z",
          "shell.execute_reply": "2024-10-22T19:21:59.201731Z"
        }
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "# To get the value of the max sequence_length, we will query the underlying `SentenceTransformer` object used for embeddings\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "print(f\"Model's maximum sequence length: {SentenceTransformer('all-mpnet-base-v2').max_seq_length}\")"
      ],
      "metadata": {
        "id": "CBsNAPtKiiZM",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:21:59.204420Z",
          "iopub.execute_input": "2024-10-22T19:21:59.204877Z",
          "iopub.status.idle": "2024-10-22T19:22:23.987799Z",
          "shell.execute_reply.started": "2024-10-22T19:21:59.204841Z",
          "shell.execute_reply": "2024-10-22T19:22:23.986601Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb693ac-a722-4e2c-cb73-9c4fb57430ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's maximum sequence length: 384\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "\n",
        "# Split text into chunks\n",
        "\n",
        "TEXT_SEPARATORS = [\n",
        "\n",
        "    \"\\n\\n\",\n",
        "\n",
        "    \"\\n\",\n",
        "\n",
        "    \".\",\n",
        "\n",
        "    \" \",\n",
        "\n",
        "    \"\",\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "\n",
        "    chunk_size=384-64, # selected to stay under 384 max size for all-mpnet-base-v2\n",
        "\n",
        "    chunk_overlap=50, # arbitrarily pick how much across chunks\n",
        "\n",
        "    add_start_index=True,  # If `True`, includes chunk's start index in metadata\n",
        "\n",
        "    strip_whitespace=True,  # If `True`, strips whitespace from the start and end of every document\n",
        "\n",
        "    separators=TEXT_SEPARATORS,\n",
        "\n",
        ")\n",
        "\n",
        "texts = []\n",
        "\n",
        "metadatas = []\n",
        "\n",
        "\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "\n",
        "    try:\n",
        "\n",
        "      chunks = text_splitter.split_text(row['text'])\n",
        "\n",
        "      texts.extend(chunks)\n",
        "\n",
        "      metadatas.extend([{'source': row['source']}] * len(chunks))\n",
        "\n",
        "    except:\n",
        "\n",
        "      print(f\"source {row['source']} corrupted\")"
      ],
      "metadata": {
        "id": "oZlCrH_Sb8mF",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:22:23.990737Z",
          "iopub.execute_input": "2024-10-22T19:22:23.991580Z",
          "iopub.status.idle": "2024-10-22T19:22:30.164664Z",
          "shell.execute_reply.started": "2024-10-22T19:22:23.991541Z",
          "shell.execute_reply": "2024-10-22T19:22:30.163829Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f3a1365-5aa7-453e-b706-ee99affa504e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source https://onestoppgh.pittsburghpa.gov/pghprod/pub/lms/Login.aspx corrupted\n",
            "source https://www.cmu.edu/dietrich/rss-feeds/news-rss.rss corrupted\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = [len(text) for text in texts]\n",
        "\n",
        "# Plot the distribution of text lengths, counted as the number of tokens\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = pd.Series(lengths).hist()\n",
        "\n",
        "plt.title(\"Distribution of document lengths in the knowledge base (in count of tokens)\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lLYIznRkeDQ4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:22:30.201058Z",
          "iopub.execute_input": "2024-10-22T19:22:30.201618Z",
          "iopub.status.idle": "2024-10-22T19:22:30.565848Z",
          "shell.execute_reply.started": "2024-10-22T19:22:30.201582Z",
          "shell.execute_reply": "2024-10-22T19:22:30.564923Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "0a24cc69-8b57-436b-fa2c-c967c8d90d29"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import normalize\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch"
      ],
      "metadata": {
        "id": "Un1dfaqcY9Oi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Initialize the Hugging Face Embedding Model\n",
        "model_name = 'sentence-transformers/all-mpnet-base-v2'  # Example model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "embedder_model = AutoModel.from_pretrained(model_name)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "embedder_model.to(device)\n",
        "embedder_model.eval()\n",
        "\n",
        "# Step 2: Define a function to generate embeddings\n",
        "def generate_embeddings(texts, tokenizer, embedder_model, batch_size=32):\n",
        "    embeddings = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch_texts = texts[i:i + batch_size]\n",
        "            inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors='pt')\n",
        "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "            outputs = embedder_model(**inputs)\n",
        "            attention_mask = inputs['attention_mask']\n",
        "            embeddings_batch = mean_pooling(outputs, attention_mask)\n",
        "            embeddings.append(embeddings_batch.cpu().numpy())\n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output.last_hidden_state\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, dim=1)\n",
        "    sum_mask = torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9)\n",
        "    return sum_embeddings / sum_mask\n",
        "\n",
        "# Step 3: Load your texts\n",
        "# already loaded\n",
        "\n",
        "# Step 4: Generate embeddings\n",
        "embeddings = generate_embeddings(texts, tokenizer, embedder_model, batch_size=32).astype('float32')\n",
        "\n",
        "# Step 5: Dimensionality Reduction\n",
        "pca = PCA(n_components=512)\n",
        "reduced_embeddings = pca.fit_transform(embeddings)\n",
        "\n",
        "# Step 6: Normalize for Cosine Similarity\n",
        "normalized_embeddings = normalize(reduced_embeddings, norm='l2', axis=1)\n",
        "\n",
        "# Step 7: Initialize FAISS Index\n",
        "n_clusters = 1000\n",
        "m = 8\n",
        "nbits = 8\n",
        "quantizer = faiss.IndexFlatL2(normalized_embeddings.shape[1])\n",
        "index = faiss.IndexIVFPQ(quantizer, normalized_embeddings.shape[1], n_clusters, m, nbits)\n",
        "\n",
        "# Step 8: Move Index to GPU and Train\n",
        "res = faiss.StandardGpuResources()\n",
        "gpu_index = faiss.index_cpu_to_gpu(res, 0, index)\n",
        "gpu_index.train(normalized_embeddings)\n",
        "\n",
        "# Step 9: Add Embeddings to the Index\n",
        "gpu_index.add(normalized_embeddings)\n",
        "\n",
        "# Step 10: Define Batch Search Function\n",
        "def batch_search(gpu_index, query_texts, tokenizer, embedder_model, pca, batch_size=32, k=5):\n",
        "    query_embeddings = generate_embeddings(query_texts, tokenizer, embedder_model, batch_size=batch_size)\n",
        "    reduced_queries = pca.transform(query_embeddings)\n",
        "    normalized_queries = normalize(reduced_queries, norm='l2', axis=1)\n",
        "\n",
        "    results = []\n",
        "    for i in range(0, len(normalized_queries), batch_size):\n",
        "        batch = normalized_queries[i:i + batch_size]\n",
        "        D, I = gpu_index.search(batch, k)\n",
        "        results.extend(zip(D, I))\n",
        "    return results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CoC5cGJ3rLV",
        "outputId": "a1966aa5-083b-4230-f19f-bcfb21a6ddd4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reader"
      ],
      "metadata": {
        "id": "A4de5-jvO0dO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_template():\n",
        "\n",
        "  prompt_in_chat_format = [\n",
        "\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "\n",
        "      \"content\": \"\"\"Using the information contained in the context,\n",
        "        give a concise answer to the question.\n",
        "        if possible limit your answer to single or a few words for who, when, where questions.\n",
        "        wherever possible extract name, date, or title without additional explanations.\n",
        "        Respond only to the question asked, response should be concise and relevant to the question.\n",
        "        You should do short answers format responses. DO NOT PUT \"ANSWER\" BEFORE THE ANSWER.\n",
        "        Don't answer in full sentences. For example, say \"12\" instead of \"The answer is 12.\"\n",
        "        \"\"\",\n",
        "      },\n",
        "\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": \"\"\"Context:\n",
        "          {context}\n",
        "          ---\n",
        "          Here are some examples of question answer pairs:\n",
        "\n",
        "          Who is Pittsburgh named after?\n",
        "          William Pitt\n",
        "\n",
        "          What famous machine learning venue had its first conference in Pittsburgh in 1980?\n",
        "          ICML\n",
        "\n",
        "          What musical artist is performing at PPG Arena on October 13?\n",
        "          Billie Eilish\n",
        "          ---\n",
        "          Don't answer in full sentences. For example, say \"12\" instead of \"The answer is 12.\"\n",
        "          Now here is the question for you to answer:\n",
        "          {question}\n",
        "\n",
        "          \"\"\",\n",
        "      },\n",
        "\n",
        "  ]\n",
        "\n",
        "  RAG_PROMPT_TEMPLATE = inference_tokenizer.apply_chat_template(\n",
        "\n",
        "      prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n",
        "\n",
        "  )\n",
        "\n",
        "  return RAG_PROMPT_TEMPLATE\n",
        "\n",
        "def create_prompts(template, queries, contexts):\n",
        "  return [template.format(question=query, context=context) for query, context in zip(queries, contexts)]\n",
        "\n",
        "def create_contexts(queries, k=5):\n",
        "  search_results = batch_search(gpu_index, queries, tokenizer, embedder_model, pca, batch_size=32, k=k)\n",
        "  contexts = []\n",
        "  for query, (distances, indices) in zip(queries, search_results):\n",
        "    context = \"\\n\\n\".join([texts[i] for i in indices])\n",
        "    contexts.append(context)\n",
        "  return contexts"
      ],
      "metadata": {
        "id": "lygyo49_O1Nf",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:24:04.599103Z",
          "iopub.execute_input": "2024-10-22T19:24:04.599416Z",
          "iopub.status.idle": "2024-10-22T19:24:04.608775Z",
          "shell.execute_reply.started": "2024-10-22T19:24:04.599383Z",
          "shell.execute_reply": "2024-10-22T19:24:04.607818Z"
        }
      },
      "outputs": [],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "import torch\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
      ],
      "metadata": {
        "id": "pTZ9J3K8aNxQ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:24:04.609824Z",
          "iopub.execute_input": "2024-10-22T19:24:04.610113Z",
          "iopub.status.idle": "2024-10-22T19:24:05.774867Z",
          "shell.execute_reply.started": "2024-10-22T19:24:04.610081Z",
          "shell.execute_reply": "2024-10-22T19:24:05.773761Z"
        }
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "READER_MODEL_NAME = \"stabilityai/stablelm-zephyr-3b\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "\n",
        "    load_in_4bit=True,\n",
        "\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "\n",
        ")\n",
        "\n",
        "inference_tokenizer = AutoTokenizer.from_pretrained(READER_MODEL_NAME)\n",
        "\n",
        "inference_model = AutoModelForCausalLM.from_pretrained(READER_MODEL_NAME, quantization_config=bnb_config)\n",
        "\n",
        "inference_model.eval()"
      ],
      "metadata": {
        "id": "bfpSbBDQQ46S",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:24:05.776086Z",
          "iopub.execute_input": "2024-10-22T19:24:05.776444Z",
          "iopub.status.idle": "2024-10-22T19:24:40.885212Z",
          "shell.execute_reply.started": "2024-10-22T19:24:05.776407Z",
          "shell.execute_reply": "2024-10-22T19:24:40.884226Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0274c79-abbd-4a81-ec73-7af883200046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StableLmForCausalLM(\n",
              "  (model): StableLmModel(\n",
              "    (embed_tokens): Embedding(50304, 2560)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x StableLmDecoderLayer(\n",
              "        (self_attn): StableLmSdpaAttention(\n",
              "          (q_proj): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (rotary_emb): StableLmRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): StableLmMLP(\n",
              "          (gate_proj): Linear4bit(in_features=2560, out_features=6912, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=2560, out_features=6912, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=6912, out_features=2560, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2560, out_features=50304, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the prompt template\n",
        "\n",
        "template = create_template()\n",
        "\n",
        "# Initialize LLM Pipeline\n",
        "\n",
        "READER_LLM = pipeline(\n",
        "\n",
        "    model=inference_model,\n",
        "\n",
        "    tokenizer=inference_tokenizer,\n",
        "\n",
        "    task=\"text-generation\",\n",
        "\n",
        "    do_sample=True,\n",
        "\n",
        "    temperature=0.01,\n",
        "\n",
        "    repetition_penalty=1.1,\n",
        "\n",
        "    return_full_text=False,\n",
        "\n",
        "    max_new_tokens=50,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "rlVNWiLSWJR4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:24:40.886553Z",
          "iopub.execute_input": "2024-10-22T19:24:40.886894Z",
          "iopub.status.idle": "2024-10-22T19:24:40.903431Z",
          "shell.execute_reply.started": "2024-10-22T19:24:40.886858Z",
          "shell.execute_reply": "2024-10-22T19:24:40.902390Z"
        }
      },
      "outputs": [],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\"What is the nickname for Pittsburgh?\", \"Who is Pittsburgh named after?\"]\n",
        "\n",
        "contexts = create_contexts(queries, k=10)\n",
        "\n",
        "prompts = create_prompts(template, queries, contexts)\n",
        "\n",
        "for prompt in prompts:\n",
        "\n",
        "  print(READER_LLM(prompt)[0]['generated_text'])"
      ],
      "metadata": {
        "id": "KFcCtWWWWqK3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:24:40.904742Z",
          "iopub.execute_input": "2024-10-22T19:24:40.905407Z",
          "iopub.status.idle": "2024-10-22T19:25:04.592162Z",
          "shell.execute_reply.started": "2024-10-22T19:24:40.905346Z",
          "shell.execute_reply": "2024-10-22T19:25:04.591231Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5216b18-7e0d-467d-bf09-bb013db0a2fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Steel City\n",
            "Pittsburgh is named after William Pitt.\n"
          ]
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def get_answer(questions):\n",
        "\n",
        "    # Simulating a RAG system query\n",
        "\n",
        "    contexts = create_contexts(questions, k=10)\n",
        "\n",
        "    prompts = create_prompts(template, questions, contexts)\n",
        "\n",
        "    answers = []\n",
        "\n",
        "    for prompt in tqdm(prompts):\n",
        "        answers.append(READER_LLM(prompt)[0]['generated_text'])\n",
        "\n",
        "    return answers\n",
        "\n",
        "def generate_answers(input_file, output_file, batch_size=32):\n",
        "\n",
        "    with open(input_file, 'r') as file:\n",
        "\n",
        "        questions = file.readlines()\n",
        "\n",
        "    answers = []\n",
        "\n",
        "    print(\"Number of Batches: \" + str(len(questions)))\n",
        "\n",
        "    # Split questions into batches\n",
        "    for i in tqdm(range(0, len(questions), batch_size)):\n",
        "        batch_questions = questions[i:i + batch_size]  # Get a batch of questions\n",
        "        batch_questions = [q.strip() for q in batch_questions if q.strip()]  # Remove empty lines\n",
        "\n",
        "        # Get answers for the batch\n",
        "        batch_answers = get_answer(batch_questions)  # Call get_answer with the batch\n",
        "\n",
        "        # Append answers to the main list\n",
        "        for index, answer in enumerate(batch_answers):\n",
        "            answers.append(f'{answer}')  # Adjust question numbering\n",
        "\n",
        "\n",
        "    with open(output_file, 'w') as file:\n",
        "\n",
        "        for answer in answers:\n",
        "\n",
        "            file.write(answer.replace(\"\\n\", \"\\t\") + '\\n') # need replace for formatting reasons\n",
        "\n",
        "            print(answer)  # Print each answer as it's generated"
      ],
      "metadata": {
        "id": "Om0Hwr2mCT5L",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:32:27.554545Z",
          "iopub.execute_input": "2024-10-22T19:32:27.555420Z",
          "iopub.status.idle": "2024-10-22T19:32:27.565955Z",
          "shell.execute_reply.started": "2024-10-22T19:32:27.555363Z",
          "shell.execute_reply": "2024-10-22T19:32:27.564594Z"
        }
      },
      "outputs": [],
      "execution_count": 47
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage example:\n",
        "\n",
        "generate_answers(\"questions.txt\", \"generated_answers.txt\")"
      ],
      "metadata": {
        "id": "HCVCF2Vo1MBE",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:55:27.514069Z",
          "iopub.execute_input": "2024-10-22T19:55:27.514497Z",
          "iopub.status.idle": "2024-10-22T19:55:55.950096Z",
          "shell.execute_reply.started": "2024-10-22T19:55:27.514457Z",
          "shell.execute_reply": "2024-10-22T19:55:55.947251Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4732a273-1386-43f7-8805-5a7e2b9ca55c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Q's: 57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "  3%|         | 1/32 [00:04<02:06,  4.09s/it]\u001b[A\n",
            "  6%|         | 2/32 [00:06<01:37,  3.24s/it]\u001b[A\n",
            "  9%|         | 3/32 [00:09<01:27,  3.03s/it]\u001b[A\n",
            " 12%|        | 4/32 [00:13<01:34,  3.39s/it]\u001b[A\n",
            " 16%|        | 5/32 [00:17<01:35,  3.52s/it]\u001b[A\n",
            " 19%|        | 6/32 [00:19<01:20,  3.08s/it]\u001b[AYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "\n",
            " 22%|       | 7/32 [00:24<01:37,  3.89s/it]\u001b[A\n",
            " 25%|       | 8/32 [00:29<01:36,  4.03s/it]\u001b[A\n",
            " 28%|       | 9/32 [00:32<01:24,  3.68s/it]\u001b[A\n",
            " 31%|      | 10/32 [00:35<01:16,  3.48s/it]\u001b[A\n",
            " 34%|      | 11/32 [00:37<01:07,  3.23s/it]\u001b[A\n",
            " 38%|      | 12/32 [00:41<01:09,  3.47s/it]\u001b[A\n",
            " 41%|      | 13/32 [00:48<01:24,  4.46s/it]\u001b[A\n",
            " 44%|     | 14/32 [00:50<01:06,  3.72s/it]\u001b[A\n",
            " 47%|     | 15/32 [00:55<01:07,  3.97s/it]\u001b[A\n",
            " 50%|     | 16/32 [01:00<01:12,  4.50s/it]\u001b[A\n",
            " 53%|    | 17/32 [01:03<00:58,  3.90s/it]\u001b[A\n",
            " 56%|    | 18/32 [01:07<00:55,  3.95s/it]\u001b[A\n",
            " 59%|    | 19/32 [01:12<00:54,  4.16s/it]\u001b[A\n",
            " 62%|   | 20/32 [01:15<00:45,  3.83s/it]\u001b[A\n",
            " 66%|   | 21/32 [01:17<00:38,  3.47s/it]\u001b[A\n",
            " 69%|   | 22/32 [01:23<00:40,  4.05s/it]\u001b[A\n",
            " 72%|  | 23/32 [01:27<00:35,  3.95s/it]\u001b[A\n",
            " 75%|  | 24/32 [01:31<00:33,  4.15s/it]\u001b[A\n",
            " 78%|  | 25/32 [01:35<00:28,  4.08s/it]\u001b[A\n",
            " 81%| | 26/32 [01:40<00:26,  4.46s/it]\u001b[A\n",
            " 84%| | 27/32 [01:43<00:20,  4.04s/it]\u001b[A\n",
            " 88%| | 28/32 [01:49<00:17,  4.43s/it]\u001b[A\n",
            " 91%| | 29/32 [01:51<00:11,  3.77s/it]\u001b[A\n",
            " 94%|| 30/32 [01:55<00:07,  3.98s/it]\u001b[A\n",
            " 97%|| 31/32 [02:01<00:04,  4.52s/it]\u001b[A\n",
            "100%|| 32/32 [02:04<00:00,  3.90s/it]\n",
            " 50%|     | 1/2 [02:04<02:04, 124.97s/it]\n",
            "  0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|         | 1/25 [00:04<01:46,  4.43s/it]\u001b[A\n",
            "  8%|         | 2/25 [00:08<01:34,  4.10s/it]\u001b[A\n",
            " 12%|        | 3/25 [00:10<01:09,  3.18s/it]\u001b[A\n",
            " 16%|        | 4/25 [00:12<00:58,  2.80s/it]\u001b[A\n",
            " 20%|        | 5/25 [00:15<00:59,  2.98s/it]\u001b[A\n",
            " 24%|       | 6/25 [00:19<01:01,  3.24s/it]\u001b[A\n",
            " 28%|       | 7/25 [00:22<00:56,  3.12s/it]\u001b[A\n",
            " 32%|      | 8/25 [00:24<00:46,  2.75s/it]\u001b[A\n",
            " 36%|      | 9/25 [00:26<00:39,  2.47s/it]\u001b[A\n",
            " 40%|      | 10/25 [00:31<00:47,  3.20s/it]\u001b[A\n",
            " 44%|     | 11/25 [00:33<00:42,  3.05s/it]\u001b[A\n",
            " 48%|     | 12/25 [00:35<00:35,  2.76s/it]\u001b[A\n",
            " 52%|    | 13/25 [00:40<00:39,  3.29s/it]\u001b[A\n",
            " 56%|    | 14/25 [00:44<00:39,  3.63s/it]\u001b[A\n",
            " 60%|    | 15/25 [00:46<00:30,  3.07s/it]\u001b[A\n",
            " 64%|   | 16/25 [00:48<00:24,  2.70s/it]\u001b[A\n",
            " 68%|   | 17/25 [00:50<00:19,  2.42s/it]\u001b[A\n",
            " 72%|  | 18/25 [00:53<00:18,  2.58s/it]\u001b[A\n",
            " 76%|  | 19/25 [00:55<00:14,  2.49s/it]\u001b[A\n",
            " 80%|  | 20/25 [00:58<00:13,  2.65s/it]\u001b[A\n",
            " 84%| | 21/25 [01:01<00:11,  2.88s/it]\u001b[A\n",
            " 88%| | 22/25 [01:03<00:07,  2.60s/it]\u001b[A\n",
            " 92%|| 23/25 [01:05<00:04,  2.42s/it]\u001b[A\n",
            " 96%|| 24/25 [01:13<00:03,  3.85s/it]\u001b[A\n",
            "100%|| 25/25 [01:15<00:00,  3.01s/it]\n",
            "100%|| 2/2 [03:20<00:00, 100.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1: Answer: Not applicable, as the context provided does not contain information about the Pirates' first home game of the 2025 season.\n",
            "Question 2: Ben Roethlisberger\n",
            "Question 3: October 23, 6:00 PM - 9:00 PM\n",
            "Question 4: Pittsburgh won their first Super Bowl title in 1972.\n",
            "Question 5: Top Dog House booth for 2023 at CMU's Spring Carnival: Society of Asian Scientists and Engineers\n",
            "Question 6: Answer: KeBryan Hayes\n",
            "Question 7: Tre Tipton  2021 (People's Choice Award)\n",
            "Question 8: April 11, 2025, 7:30 p.m., PA 15222\n",
            "Question 9: Mike Tomlin, hired prior to the 2007 season.\n",
            "Question 10: November 9, 2024, 1:00pm - 3:00pm EST\n",
            "Question 11: 9:30PM-12:30AM\n",
            "Question 12: Title: \"Examining Nation-State Interference in U.S. Elections\"\n",
            "Question 13: Answer: 7:00 PM\n",
            "\n",
            "Extracted information: \n",
            "\n",
            "- Date: Jan 11, 2025\n",
            "- Time: 7:00 PM\n",
            "- Event: Ottawa Senators at Pittsburgh Penguins\n",
            "- Venue: PPG Paints Arena\n",
            "Question 14: 7-10 p.m.\n",
            "Question 15: As of June 12, 2019, Bill Mazeroski is the oldest player on the Pittsburgh Pirates roster, having played for the team from 1955-1972.\n",
            "Question 16: Event: Angelmakers: Songs for Female Serial Killers\n",
            "  Venue: Funhouse @ Mr. Smalls\n",
            "  Date: Not specified in provided context\n",
            "  Host: Not specified in provided context\n",
            "  Description: Concert-play exploring female\n",
            "Question 17: Six. Answer: Six.\n",
            "Question 18: PhD Support Group on October 28, 2024, offered by Jayme Jenkins, PhD.\n",
            "Question 19: Pittsburgh played against the Dallas Cowboys in Week 1 of the regular season. The result was a match held on September 9, 2001, with the Steelers losing 25-23.\n",
            "Question 20: Venue: Carnegie Music Hall\n",
            "Question 21: Acrisure Stadium\n",
            "Question 22: The question you provided doesn't contain information about the specific team the Pirates are facing on May 2, 2025, at home. Therefore, it's impossible to provide a concise answer to this question using the given context.\n",
            "Question 23: Steelers' Week 10 opponents: Baltimore Ravens, Acrisure Stadium (Pittsburgh, PA)\n",
            "Question 24: Chris Boswell is the Pittsburgh Steelers' kicker, and he has been in the NFL for 8 years (2013-2020).\n",
            "Question 25: Rose Way, Near The Warhol. \n",
            "\n",
            "Answer: Limited context provided. Pittsburgh International Auto Show details not available.\n",
            "Question 26: CMU Buggy races include \"Buggy,\" an uphill relay race with batons as vehicles, and downhill gravity racing with speeds up to 40mph and sharp turns. Students design and build aerodynamic cylinders for these races.\n",
            "Question 27: Clemente. Answer: Roberto Clemente.\n",
            "Question 28: Steelers vs. Green Bay Packers, Wisconsin\n",
            "\n",
            "(Note: The user requested a concise answer to the question about the Steelers' opponents and location for Week 3 game, so I provided the names of the teams involved and the location where the\n",
            "Question 29: Jolly Roger Wall\n",
            "Question 30: Answer: RW, 21.\n",
            "Please provide the answer in the requested format: \"Position, Jersey Number\".\n",
            "Question 31: Allegheny County existed prior to 1787, when it was formed from Westmoreland County and became the Sinking Spring Precinct. It later gained its present name, Allegheny County, in 1789.\n",
            "Question 32: Pittsburgh experienced severe flooding in 1936, leading to significant changes in infrastructure.\n",
            "Question 33: Smoke Control Ordinance enforcement and efforts to improve air quality, such as the crowd-sourced air quality monitoring app Smell PGH.\n",
            "Question 34: West Mifflin\n",
            "\n",
            "Answer: National Aviary is located in West Mifflin neighborhood.\n",
            "Question 35: 1863\n",
            "Question 36: High Hill\n",
            "Question 37: Pittsburgh Aviary was designated as the National Aviary in 1924.\n",
            "Question 38: DTP (diphtheria, tetanus, and pertussis) vaccine\n",
            "Question 39: Answer: Point State Park (1,248 feet)\n",
            "Question 40: KDKA-AM\n",
            "Question 41: 1952\n",
            "Question 42: Point Park University established Conservatory Performing Arts offering degree programs in theater, dance, and music-related fields in 1992.\n",
            "Question 43: Monongahela River Trailhead Park\n",
            "Question 44: Scott Fahlman\n",
            "Question 45: PNC Park sits on the banks of the Allegheny River in Pittsburgh's North Side neighborhood, hosting home games for the Pittsburgh Pirates MLB team.\n",
            "Question 46: Margaret Morrison Carnegie College closed in 1969 and merged with other programs at CMU in 1970, becoming Carnegie Mellon University.\n",
            "Question 47: 1875\n",
            "Question 48: 1900\n",
            "Question 49: Walter Brattain\n",
            "Question 50: Pittsburgh was founded on November 27, 1758.\n",
            "Question 51: 1978\n",
            "Question 52: Fort Stanwix Treaty of 1768\n",
            "Question 53: Pittsburgh's nickname is related to its bridges as \"City of Bridges.\"\n",
            "Question 54: 1921\n",
            "Question 55: Carnegie Mellon University\n",
            "Question 56: Name: Carnegie Mellon University (CMU)\n",
            "Event: Spring Carnival Homecoming Reunion Alumni Awards\n",
            "Date: April 3-5, 2025\n",
            "Question: What annual event showcases student projects and research across disciplines at CMU\n",
            "Question 57: Picklesburgh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "C5r65cE30nM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "# Function to normalize text by removing articles and punctuation and lowercasing\n",
        "\n",
        "def normalize_answer(s):\n",
        "\n",
        "    def remove_articles(text):\n",
        "\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "\n",
        "    def remove_punctuation(text):\n",
        "\n",
        "        return re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "\n",
        "\n",
        "    def lowercase(text):\n",
        "\n",
        "        return text.lower()\n",
        "\n",
        "\n",
        "\n",
        "    return remove_articles(remove_punctuation(lowercase(s))).strip()\n",
        "\n",
        "\n",
        "\n",
        "# Function to compute Exact Match (EM)\n",
        "\n",
        "def exact_match_score(prediction, ground_truth):\n",
        "\n",
        "    return int(normalize_answer(prediction) == normalize_answer(ground_truth))\n",
        "\n",
        "\n",
        "\n",
        "# Function to compute F1 Score\n",
        "\n",
        "def f1_score_single(prediction, ground_truth):\n",
        "\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "\n",
        "\n",
        "\n",
        "    common_tokens = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "\n",
        "    num_same = sum(common_tokens.values())\n",
        "\n",
        "\n",
        "\n",
        "    if num_same == 0:\n",
        "\n",
        "        return 0\n",
        "\n",
        "\n",
        "\n",
        "    precision = num_same / len(prediction_tokens)\n",
        "\n",
        "    recall = num_same / len(ground_truth_tokens)\n",
        "\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "\n",
        "\n",
        "    return f1\n",
        "\n",
        "\n",
        "\n",
        "# Function to compute recall\n",
        "\n",
        "def recall_score_single(prediction, ground_truth):\n",
        "\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "\n",
        "\n",
        "\n",
        "    common_tokens = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "\n",
        "    num_same = sum(common_tokens.values())\n",
        "\n",
        "\n",
        "\n",
        "    if len(ground_truth_tokens) == 0:\n",
        "\n",
        "        return 0\n",
        "\n",
        "    recall = num_same / len(ground_truth_tokens)\n",
        "\n",
        "    return recall"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:25:05.099918Z",
          "iopub.status.idle": "2024-10-22T19:25:05.100323Z",
          "shell.execute_reply.started": "2024-10-22T19:25:05.100110Z",
          "shell.execute_reply": "2024-10-22T19:25:05.100129Z"
        },
        "id": "k7OjTSdG0nM_"
      },
      "outputs": [],
      "execution_count": 44
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the reference and generated answers\n",
        "\n",
        "with open('reference_answers.txt', 'r') as f:\n",
        "\n",
        "    reference_answers = f.readlines()\n",
        "\n",
        "\n",
        "\n",
        "with open('generated_answers.txt', 'r') as f:\n",
        "\n",
        "    generated_answers = f.readlines()\n",
        "\n",
        "\n",
        "\n",
        "# Ensure the files have the same number of answers\n",
        "\n",
        "assert len(reference_answers) == len(generated_answers), \"Mismatch in number of answers.\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:25:05.101925Z",
          "iopub.status.idle": "2024-10-22T19:25:05.102288Z",
          "shell.execute_reply.started": "2024-10-22T19:25:05.102099Z",
          "shell.execute_reply": "2024-10-22T19:25:05.102116Z"
        },
        "id": "wSWxeuvU0nNA"
      },
      "outputs": [],
      "execution_count": 45
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics\n",
        "\n",
        "total_em = 0\n",
        "\n",
        "total_f1 = 0\n",
        "\n",
        "total_recall = 0\n",
        "\n",
        "\n",
        "\n",
        "# Iterate over all answers and compute metrics\n",
        "\n",
        "for ref_answer, gen_answer in zip(reference_answers, generated_answers):\n",
        "\n",
        "    em = exact_match_score(gen_answer.strip(), ref_answer.strip())\n",
        "\n",
        "    f1 = f1_score_single(gen_answer.strip(), ref_answer.strip())\n",
        "\n",
        "    recall = recall_score_single(gen_answer.strip(), ref_answer.strip())\n",
        "\n",
        "\n",
        "\n",
        "    total_em += em\n",
        "\n",
        "    total_f1 += f1\n",
        "\n",
        "    total_recall += recall\n",
        "\n",
        "# Average the metrics over all the questions\n",
        "\n",
        "num_questions = len(reference_answers)\n",
        "\n",
        "average_em = total_em / num_questions\n",
        "\n",
        "average_f1 = total_f1 / num_questions\n",
        "\n",
        "average_recall = total_recall / num_questions\n",
        "\n",
        "\n",
        "\n",
        "# Display the results\n",
        "\n",
        "print(f\"Exact Match: {average_em * 100:.2f}%\")\n",
        "\n",
        "print(f\"F1 Score: {average_f1 * 100:.2f}%\")\n",
        "\n",
        "print(f\"Recall: {average_recall * 100:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-22T19:25:05.103716Z",
          "iopub.status.idle": "2024-10-22T19:25:05.104199Z",
          "shell.execute_reply.started": "2024-10-22T19:25:05.103892Z",
          "shell.execute_reply": "2024-10-22T19:25:05.103911Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5TNkxRr0nNA",
        "outputId": "514b308b-d65d-401e-9082-9068fbe8a214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact Match: 5.26%\n",
            "F1 Score: 25.77%\n",
            "Recall: 36.43%\n"
          ]
        }
      ],
      "execution_count": 46
    }
  ]
}